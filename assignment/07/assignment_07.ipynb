{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_07_solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2d98f760a7cb4eb98b9d23ce99f7525c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_42c691e2b622437ebf3bf0ce9edf5586",
              "IPY_MODEL_aaf80371b1204d38b28a9e5ea4f28c99",
              "IPY_MODEL_fbea50abc9e14efb890d88724d9e3615"
            ],
            "layout": "IPY_MODEL_4f1358cc66244198bed435b78f7b24c4"
          }
        },
        "42c691e2b622437ebf3bf0ce9edf5586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c5a6ee2b2194c5d9c20d6c8cb6d1d84",
            "placeholder": "​",
            "style": "IPY_MODEL_19f09148d6c44147ae7e0a5983521466",
            "value": "  0%"
          }
        },
        "aaf80371b1204d38b28a9e5ea4f28c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d7a19f86e4f406ca6f0a0535d941570",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5aabcdb26c648bfbc53c0600e24b90b",
            "value": 0
          }
        },
        "fbea50abc9e14efb890d88724d9e3615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb263debfa924d8da0622d20545c298c",
            "placeholder": "​",
            "style": "IPY_MODEL_ad2ff258f31c4ff091d8a02d714f916a",
            "value": " 0/300 [00:00&lt;?, ?it/s]"
          }
        },
        "4f1358cc66244198bed435b78f7b24c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c5a6ee2b2194c5d9c20d6c8cb6d1d84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f09148d6c44147ae7e0a5983521466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d7a19f86e4f406ca6f0a0535d941570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5aabcdb26c648bfbc53c0600e24b90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb263debfa924d8da0622d20545c298c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad2ff258f31c4ff091d8a02d714f916a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63aOEusN1Tgf"
      },
      "source": [
        "# Supervised image denoising"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCIAhtbr1Yhs"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xzQSB-t95mT"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage, Resize, Lambda, Normalize, Grayscale\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from math import log10\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fvdQA9THZPs"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckroXmQgHbCb",
        "outputId": "d85295a2-ae4b-4069-a339-ff9458c6f657"
      },
      "source": [
        "directory_data  = './'\n",
        "filename_data   = 'assignment_07_data.npz'\n",
        "data            = np.load(os.path.join(directory_data, filename_data))\n",
        "\n",
        "\n",
        "original_train = data['original_train'] \n",
        "noise_train    = data['noise_train']\n",
        "\n",
        "original_test = data['original_test'] \n",
        "noise_test    = data['noise_test']\n",
        "\n",
        "print('*************************************************')\n",
        "print('size of original_train : ', original_train.shape)\n",
        "print('size of noise_train    : ', noise_train.shape)\n",
        "print('*************************************************')\n",
        "print('size of original_test : ', original_test.shape)\n",
        "print('size of noise_test    : ', noise_test.shape)\n",
        "print('*************************************************')\n",
        "print('number of training image :', original_train.shape[0])\n",
        "print('height of training image :', original_train.shape[1])\n",
        "print('width of training image  :', original_train.shape[2])\n",
        "print('*************************************************')\n",
        "print('number of testing image :', original_test.shape[0])\n",
        "print('height of testing image :', original_test.shape[1])\n",
        "print('width of testing image  :', original_test.shape[2])\n",
        "print('*************************************************')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "size of original_train :  (2000, 64, 64)\n",
            "size of noise_train    :  (2000, 64, 64)\n",
            "*************************************************\n",
            "size of original_test :  (900, 64, 64)\n",
            "size of noise_test    :  (900, 64, 64)\n",
            "*************************************************\n",
            "number of training image : 2000\n",
            "height of training image : 64\n",
            "width of training image  : 64\n",
            "*************************************************\n",
            "number of testing image : 900\n",
            "height of testing image : 64\n",
            "width of testing image  : 64\n",
            "*************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1hicXomGrkw"
      },
      "source": [
        "## Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GAHfVd2G0ev"
      },
      "source": [
        "device        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "number_epoch    = 200\n",
        "size_minibatch  = 100\n",
        "learning_rate   = 0.002\n",
        "momentum        = 0.9\n",
        "weight_decay    = 0.0001"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asN2O6HH1cdK"
      },
      "source": [
        "## Costumize dataloader for pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHWHWu9p-Bs5"
      },
      "source": [
        "class dataset (Dataset):\n",
        "  def  __init__(self, original,noise):\n",
        "\n",
        "    self.original = original\n",
        "    self.noise    = noise\n",
        "        \n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    original    = self.original[index]\n",
        "    noise       = self.noise[index]\n",
        "    \n",
        "    original   = torch.FloatTensor(original).unsqueeze(dim=0)\n",
        "    noise      = torch.FloatTensor(noise).unsqueeze(dim=0)\n",
        "\n",
        "\n",
        "    return (original , noise)\n",
        "  \n",
        "  def __len__(self):\n",
        "\n",
        "     return self.original.shape[0]\n",
        "     "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1RYZQkkJm78"
      },
      "source": [
        "## Construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwKkQ4Hw-Fkb"
      },
      "source": [
        "dataset_train = dataset(original_train, noise_train) \n",
        "dataset_test  = dataset(original_test, noise_test) \n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, num_workers=2)\n",
        "dataloader_test  = DataLoader(dataset_test,  batch_size=size_minibatch, shuffle=False, drop_last=True, num_workers=2) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZd1kMmRX12L"
      },
      "source": [
        "## Shape of the data with data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0Df5ivSX12M",
        "outputId": "15e174b5-8592-473c-e8e8-ca91f94e9041"
      },
      "source": [
        "(original_train, noise_train)   = dataset_train[0]\n",
        "(original_test, noise_test)     = dataset_test[0]\n",
        "\n",
        "print('************************************************************')\n",
        "print('shape of the original image in the training dataset:', original_train.shape)\n",
        "print('shape of the noisy image in the training dataset:', noise_train.shape)\n",
        "print('************************************************************')\n",
        "print('shape of the original image in the testing dataset:', original_test.shape)\n",
        "print('shape of the noisy image in the testing dataset:', noise_test.shape)\n",
        "print('************************************************************')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************************************************\n",
            "shape of the original image in the training dataset: torch.Size([1, 64, 64])\n",
            "shape of the noisy image in the training dataset: torch.Size([1, 64, 64])\n",
            "************************************************************\n",
            "shape of the original image in the testing dataset: torch.Size([1, 64, 64])\n",
            "shape of the noisy image in the testing dataset: torch.Size([1, 64, 64])\n",
            "************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ngJeHXH2dfj"
      },
      "source": [
        "## Class for the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cp9EIWuU-Bkk"
      },
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Network,self).__init__()\n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # Encoder\n",
        "        # -------------------------------------------------\n",
        "        \n",
        "        self.e_layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(1,32,3,padding=1),#batch*32*28*28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,32,3,padding=1),#batch*32*28*28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,64,3,padding=1),#batch*64*28*28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.Conv2d(64,64,3,padding=1),#batch*64*28*28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.MaxPool2d(2,2),#batch*64*14*14\n",
        "                        nn.Conv2d(64,128,3,padding=1),#batch*128*14*14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.Conv2d(128,128,3,padding=1),#batch*128*14*14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.MaxPool2d(2,2),\n",
        "                        nn.Conv2d(128,256,3,padding=1),#batch*256*14*14\n",
        "                        nn.ReLU()\n",
        "\n",
        "        )\n",
        "        \n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # Decoder\n",
        "        # -------------------------------------------------\n",
        "        self.d_layer1 = nn.Sequential(\n",
        "                        nn.ConvTranspose2d(256,128,3,2,1,1),#batch*128*14*14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ConvTranspose2d(128,128,3,1,1),#batch*128*14*14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ConvTranspose2d(128,64,3,1,1),#batch*64*14*14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ConvTranspose2d(64,64,3,1,1),#batch*64*14*14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ConvTranspose2d(64,32,3,1,1),#batch*32*14*14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,32,3,1,1),#batch*32*14*14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,1,3,2,1,1),#batch*1*28*28\n",
        "                        nn.ReLU(),\n",
        "\n",
        "\n",
        "                        # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                        # nn.Conv2d(in_channels=256, out_channels=128, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "                        # nn.ReLU(),\n",
        "                        # nn.BatchNorm2d(128),\n",
        "                                           \n",
        "                        # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                        # nn.Conv2d(in_channels=128, out_channels=64, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "                        # nn.ReLU(),\n",
        "                        # nn.BatchNorm2d(64),\n",
        "\n",
        "                        # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                        # nn.Conv2d(in_channels=64, out_channels=32, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "                        # nn.ReLU(),\n",
        "                        # nn.BatchNorm2d(32),\n",
        "\n",
        "                        # nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "                        # nn.Conv2d(in_channels=32, out_channels=1, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "                        # nn.ReLU(),\n",
        "                        # nn.BatchNorm2d(1),\n",
        "                        nn.Sigmoid()\n",
        "        )\n",
        "        \n",
        "\n",
        "        # -------------------------------------------------\n",
        "        # Network\n",
        "        # -------------------------------------------------\n",
        "        self.network = nn.Sequential(\n",
        "                        self.e_layer1,\n",
        "                        self.d_layer1\n",
        "        )\n",
        "\n",
        "        self.initialize_weight()\n",
        "\n",
        "    def forward(self,x):\n",
        "    \n",
        "        out = self.network(x)\n",
        "      \n",
        "        return out\n",
        "\n",
        "    # ======================================================================\n",
        "    # initialize weights\n",
        "    # ======================================================================\n",
        "    def initialize_weight(self):\n",
        "        for m in self.network.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.constant_(m.weight, 0.1) \n",
        "                \n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 1)\n",
        "                    pass\n",
        "                    \n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 1)\n",
        "                \n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.weight, 0.1) \n",
        "\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 1)\n",
        "                    pass"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjlHwUOV-UCh"
      },
      "source": [
        "# class Network(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(Network,self).__init__()\n",
        "\n",
        "#         # -------------------------------------------------\n",
        "#         # Encoder\n",
        "#         # -------------------------------------------------\n",
        "        \n",
        "#         self.e_layer1 = nn.Sequential(\n",
        "#                         nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True),  \n",
        "#                         nn.MaxPool2d(2,2),\n",
        "#                         nn.ReLU(),\n",
        "#                         nn.BatchNorm2d(8),\n",
        "#         )\n",
        "        \n",
        "#         self.e_layer2 = nn.Sequential(\n",
        "#                         nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "#                         nn.MaxPool2d(2,2),\n",
        "#                         nn.ReLU(),\n",
        "#                         nn.BatchNorm2d(16),\n",
        "#         )\n",
        "\n",
        "#         # -------------------------------------------------\n",
        "#         # Decoder\n",
        "#         # -------------------------------------------------\n",
        "#         self.d_layer1 = nn.Sequential(\n",
        "#                         nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "#                         nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "#                         nn.ReLU(),\n",
        "#                         nn.BatchNorm2d(8),\n",
        "#         )\n",
        "        \n",
        "#         self.d_layer2 = nn.Sequential(\n",
        "#                         nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
        "#                         nn.Conv2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "#                         nn.Sigmoid(),\n",
        "#         )\n",
        "\n",
        "#         # -------------------------------------------------\n",
        "#         # Network\n",
        "#         # -------------------------------------------------\n",
        "#         self.network = nn.Sequential(\n",
        "#                         self.e_layer1,\n",
        "#                         self.e_layer2,\n",
        "#                         self.d_layer1, \n",
        "#                         self.d_layer2,\n",
        "#         )\n",
        "\n",
        "#         self.initialize_weight()\n",
        "\n",
        "#     def forward(self,x):\n",
        "    \n",
        "#         out = self.network(x)\n",
        "      \n",
        "#         return out\n",
        "\n",
        "#     # ======================================================================\n",
        "#     # initialize weights\n",
        "#     # ======================================================================\n",
        "#     def initialize_weight(self):\n",
        "            \n",
        "#         for m in self.network.modules():\n",
        "            \n",
        "#             if isinstance(m, nn.Conv2d):\n",
        "\n",
        "#                 nn.init.constant_(m.weight, 0.1) \n",
        "                \n",
        "#                 if m.bias is not None:\n",
        "\n",
        "#                     nn.init.constant_(m.bias, 1)\n",
        "#                     pass\n",
        "                    \n",
        "#             elif isinstance(m, nn.BatchNorm2d):\n",
        "                \n",
        "#                 nn.init.constant_(m.weight, 1)\n",
        "#                 nn.init.constant_(m.bias, 1)\n",
        "                \n",
        "#             elif isinstance(m, nn.Linear):\n",
        "                \n",
        "#                 nn.init.constant_(m.weight, 0.1) \n",
        "\n",
        "#                 if m.bias is not None:\n",
        "                    \n",
        "#                     nn.init.constant_(m.bias, 1)\n",
        "#                     pass"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTXZnsrGLoxg"
      },
      "source": [
        "## Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsGGOsXKLuc1"
      },
      "source": [
        "model = Network().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum , weight_decay=weight_decay)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yE9LChkQ5G2"
      },
      "source": [
        "## Compute prediction (denoised image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mgS8kzGQ502"
      },
      "source": [
        "def compute_prediction(model, input):\n",
        "\n",
        "    denoise = model(input)\n",
        "\n",
        "    return denoise"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQVz0ChdM9KL"
      },
      "source": [
        "## Compute loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbvdtlxKNAmm"
      },
      "source": [
        "def compute_loss(noise, original):\n",
        "\n",
        "    criterion   = nn.MSELoss()\n",
        "    loss        = criterion(noise, original)\n",
        "    loss_value  = loss.item()\n",
        "\n",
        "    return loss, loss_value"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKGc41X7NZ_M"
      },
      "source": [
        "## Compute PSNR metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVXKX82D9k20"
      },
      "source": [
        "def compute_PSNR (loss):\n",
        "\n",
        "  if (loss==0.):\n",
        "    PSNR=100\n",
        "  else :\n",
        "    PSNR=10*log10(1/loss)\n",
        "\n",
        "  return PSNR"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UIl4gCp2hE6"
      },
      "source": [
        "## Variable for the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXs-w_99-cuZ"
      },
      "source": [
        "loss_mean_train     = np.zeros(number_epoch)\n",
        "loss_std_train      = np.zeros(number_epoch)\n",
        "PSNR_mean_train     = np.zeros(number_epoch)\n",
        "PSNR_std_train      = np.zeros(number_epoch)\n",
        "\n",
        "loss_mean_test      = np.zeros(number_epoch)\n",
        "loss_std_test       = np.zeros(number_epoch)\n",
        "PSNR_mean_test      = np.zeros(number_epoch)\n",
        "PSNR_std_test       = np.zeros(number_epoch)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7HWScczDn6S"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3p34UDlDqWg"
      },
      "source": [
        "def train(model, dataloader):\n",
        "\n",
        "    loss_epoch      = []\n",
        "    psnr_epoch      = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for index_batch, (original, noise) in enumerate(dataloader):\n",
        "\n",
        "        original = original.to(device)\n",
        "        noise    = noise.to(device)\n",
        "        # ================================================================================ \n",
        "        # complete the following codes \n",
        "        # \n",
        "        denoise             = compute_prediction(model, noise)\n",
        "        loss, loss_value    = compute_loss(denoise, original)\n",
        "        # ================================================================================ \n",
        "        psnr                = compute_PSNR(loss_value)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_epoch.append(loss_value)\n",
        "        psnr_epoch.append(psnr)\n",
        "\n",
        "    loss_mean_epoch     = np.mean(loss_epoch)\n",
        "    loss_std_epoch      = np.std(loss_epoch)\n",
        "\n",
        "    psnr_mean_epoch = np.mean(psnr_epoch)\n",
        "    psnr_std_epoch  = np.std(psnr_epoch)\n",
        "\n",
        "    loss        = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
        "    psnr        = {'mean' : psnr_mean_epoch, 'std' : psnr_std_epoch}\n",
        "\n",
        "    return (loss, psnr)    \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C783v5uJE1Y9"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJz-987xE38P"
      },
      "source": [
        "def test(model, dataloader):\n",
        "\n",
        "    loss_epoch      = []\n",
        "    psnr_epoch      = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for index_batch, (original, noise) in enumerate(dataloader):\n",
        "\n",
        "        original = original.to(device)\n",
        "        noise    = noise.to(device)\n",
        "        \n",
        "        # ================================================================================ \n",
        "        # complete the following codes \n",
        "        # \n",
        "        denoise             = compute_prediction(model, noise)\n",
        "        loss, loss_value    = compute_loss(denoise, original)\n",
        "        # ================================================================================ \n",
        "        psnr                = compute_PSNR(loss_value)\n",
        "\n",
        "        loss_epoch.append(loss_value)\n",
        "        psnr_epoch.append(psnr)\n",
        "\n",
        "    loss_mean_epoch     = np.mean(loss_epoch)\n",
        "    loss_std_epoch      = np.std(loss_epoch)\n",
        "\n",
        "    psnr_mean_epoch = np.mean(psnr_epoch)\n",
        "    psnr_std_epoch  = np.std(psnr_epoch)\n",
        "\n",
        "    loss        = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
        "    psnr        = {'mean' : psnr_mean_epoch, 'std' : psnr_std_epoch}\n",
        "\n",
        "    return (loss, psnr)    "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9ZcyzVkFsex"
      },
      "source": [
        "## train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2d98f760a7cb4eb98b9d23ce99f7525c",
            "42c691e2b622437ebf3bf0ce9edf5586",
            "aaf80371b1204d38b28a9e5ea4f28c99",
            "fbea50abc9e14efb890d88724d9e3615",
            "4f1358cc66244198bed435b78f7b24c4",
            "7c5a6ee2b2194c5d9c20d6c8cb6d1d84",
            "19f09148d6c44147ae7e0a5983521466",
            "9d7a19f86e4f406ca6f0a0535d941570",
            "a5aabcdb26c648bfbc53c0600e24b90b",
            "fb263debfa924d8da0622d20545c298c",
            "ad2ff258f31c4ff091d8a02d714f916a"
          ]
        },
        "id": "l6Qtqgv8-fMW",
        "outputId": "d886db57-5d41-4d00-dd8e-dcca354d8126"
      },
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    (loss_train, psnr_train) = train(model, dataloader_train)\n",
        "\n",
        "    loss_mean_train[i]      = loss_train['mean']\n",
        "    loss_std_train[i]       = loss_train['std']\n",
        "\n",
        "    PSNR_mean_train[i]  = psnr_train['mean']\n",
        "    PSNR_std_train[i]   = psnr_train['std']\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    (loss_test, psnr_test) = test(model, dataloader_test)\n",
        "\n",
        "    loss_mean_test[i]      = loss_test['mean']\n",
        "    loss_std_test[i]       = loss_test['std']\n",
        "\n",
        "    PSNR_mean_test[i]  = psnr_test['mean']\n",
        "    PSNR_std_test[i]   = psnr_test['std']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/300 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d98f760a7cb4eb98b9d23ce99f7525c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9RWomhwgpiM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRwqJtn9glD5"
      },
      "source": [
        "# DO NOT MODIFY THE CODES FROM HERE, BUT EXECUTE THEM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ukjE6pAgqlq"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVugi_Pi256d"
      },
      "source": [
        "## Plot functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp50r3lh-o-P"
      },
      "source": [
        "def plot_data_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * 3, nRow * 3))\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bEBS7q5-jYh"
      },
      "source": [
        "def plot_data_tensor_grid(data, index_data, nRow, nCol):\n",
        "    \n",
        "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * 3, nRow * 3))\n",
        "\n",
        "    data = data.detach().cpu().squeeze(axis=1)\n",
        "\n",
        "    for i in range(nRow):\n",
        "        for j in range(nCol):\n",
        "\n",
        "            k       = i * nCol + j\n",
        "            index   = index_data[k]\n",
        "\n",
        "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
        "            axes[i, j].xaxis.set_visible(False)\n",
        "            axes[i, j].yaxis.set_visible(False)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-5kFhCn-maa"
      },
      "source": [
        "def plot_curve_error(data_mean, data_std, x_label, y_label, title):\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    alpha = 0.3\n",
        "    \n",
        "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
        "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x-lgRuxlWY5"
      },
      "source": [
        "def print_curve(data, index):\n",
        "    \n",
        "    for i in range(len(index)):\n",
        "\n",
        "        idx = index[i]\n",
        "        val = data[idx]\n",
        "\n",
        "        print('index = %2d, value = %12.10f' % (idx, val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jabaN70hlZA1"
      },
      "source": [
        "def get_data_last(data, index_start):\n",
        "\n",
        "    data_last = data[index_start:]\n",
        "\n",
        "    return data_last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAk1QIYMleCQ"
      },
      "source": [
        "def get_max_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.max()\n",
        "\n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXluWDRPOErr"
      },
      "source": [
        "def get_min_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.min()\n",
        "\n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KZrNorBOIzA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCp_QnbqhIlv"
      },
      "source": [
        "# functions for presenting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS6Lkh9LOJop"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJI8yG5xmBEA"
      },
      "source": [
        "def function_result_01():\n",
        "\n",
        "    print('[plot examples of the training clean images]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 5 \n",
        "    nCol = 4\n",
        "    index_data  = np.arange(0, nRow * nCol)\n",
        "    original_train = dataset_train.original[index_data]\n",
        "\n",
        "    plot_data_grid(original_train, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBizLSHz-4kV"
      },
      "source": [
        "def function_result_02():\n",
        "\n",
        "    print('[plot examples of the training noisy images]')\n",
        "    print('') \n",
        "    \n",
        "    nRow = 5\n",
        "    nCol = 4\n",
        "    index_data  = np.arange(0, nRow * nCol)\n",
        "    noise_train = dataset_train.noise[index_data]\n",
        "\n",
        "    plot_data_grid(noise_train, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK4jOaFz-7Ih"
      },
      "source": [
        "def function_result_03():\n",
        "\n",
        "    print('[plot examples of the training denoising results]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 5\n",
        "    nCol = 4\n",
        "    index_data          = np.arange(0, nRow * nCol)\n",
        "    image_train         = torch.FloatTensor(dataset_train.original[index_data]).unsqueeze(dim=1).to(device)\n",
        "    prediction_train    = compute_prediction(model, image_train)\n",
        "    \n",
        "    plot_data_tensor_grid(prediction_train, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jyif5Mul_JA3"
      },
      "source": [
        "def function_result_04():\n",
        "\n",
        "    print('[plot examples of the testing clean images]')\n",
        "    print('') \n",
        "    \n",
        "    nRow = 5\n",
        "    nCol = 4\n",
        "    index_data = np.arange(0, nRow * nCol)\n",
        "    original_test = dataset_test.original[index_data]\n",
        "\n",
        "    plot_data_grid(original_test, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1R8cJd9_Mod"
      },
      "source": [
        "def function_result_05():\n",
        "\n",
        "    print('[plot examples of the testing noise images]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 5\n",
        "    nCol = 4\n",
        "    index_data = np.arange(0, nRow * nCol)\n",
        "    noise_test = dataset_test.noise[index_data]\n",
        "\n",
        "    plot_data_grid(noise_test, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3mHkTGHtv_g"
      },
      "source": [
        "def function_result_06():\n",
        "\n",
        "    print('[plot examples of the testing denoising results]')\n",
        "    print('') \n",
        "\n",
        "    nRow = 5\n",
        "    nCol = 4\n",
        "    index_data      = np.arange(0, nRow * nCol)\n",
        "    image_test      = torch.FloatTensor(dataset_test.original[index_data]).unsqueeze(dim=1).to(device)\n",
        "    prediction_test = compute_prediction(model, image_test)\n",
        "\n",
        "    plot_data_tensor_grid(prediction_test, index_data, nRow, nCol)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yQPW3wPsr9L"
      },
      "source": [
        "def function_result_07():\n",
        "\n",
        "    print('[plot the training loss]')\n",
        "    print('') \n",
        "\n",
        "    plot_curve_error(loss_mean_train, loss_std_train, 'epoch', 'loss', 'loss (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv8yfa28AfLj"
      },
      "source": [
        "def function_result_08():\n",
        "\n",
        "    print('[plot the training PSNR]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(PSNR_mean_train, PSNR_std_train, 'epoch', 'PSNR', 'PSNR (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQwA14KhBF7R"
      },
      "source": [
        "def function_result_09():\n",
        "    \n",
        "    print('[plot the testing loss]')\n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(loss_mean_test, loss_std_test, 'epoch', 'loss', 'loss (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIipA2maBQjm"
      },
      "source": [
        "def function_result_10():\n",
        "    \n",
        "    print('[plot the testing PSNR]') \n",
        "    print('') \n",
        "    \n",
        "    plot_curve_error(PSNR_mean_test, PSNR_std_test, 'epoch', 'PSNR', 'PSNR (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkV-iWvbQ8Vw"
      },
      "source": [
        "def function_result_11():\n",
        "    \n",
        "    print('[print the training loss at the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    data_last = get_data_last(loss_mean_train, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay2Sg3FFQ_TX"
      },
      "source": [
        "def function_result_12():\n",
        "    \n",
        "    print('[print the training PSNR at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last = get_data_last(PSNR_mean_train, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaocjWCbROVB"
      },
      "source": [
        "def function_result_13():\n",
        "    \n",
        "    print('[print the testing loss at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last = get_data_last(loss_mean_test, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoqxTw8RRPj6"
      },
      "source": [
        "def function_result_14():\n",
        "    \n",
        "    print('[print the testing PSNR at the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    data_last = get_data_last(PSNR_mean_test, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sb5WJWYcReyn"
      },
      "source": [
        "def function_result_15():\n",
        "    \n",
        "    print('[print the best training PSNR within the last 10 epochs]')\n",
        "    print('') \n",
        "\n",
        "    value = get_max_last_range(PSNR_mean_train, -10)\n",
        "    print('best training PSNR = %12.10f' % (value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtYAue5nRprJ"
      },
      "source": [
        "def function_result_16():\n",
        "    \n",
        "    print('[print the best testing PSNR within the last 10 epochs]')\n",
        "    print('') \n",
        "    \n",
        "    value = get_max_last_range(PSNR_mean_test, -10)\n",
        "    print('best testing PSNR = %12.10f' % (value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22XygAZhHStf"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MxxDcR4HW8j"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdjiEN4zI7Sx"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSZq5QWcm6VH"
      },
      "source": [
        "number_result = 16\n",
        "\n",
        "for i in range(number_result):\n",
        "\n",
        "    title           = '# RESULT # {:02d}'.format(i+1) \n",
        "    name_function   = 'function_result_{:02d}()'.format(i+1)\n",
        "\n",
        "    print('') \n",
        "    print('################################################################################')\n",
        "    print('#') \n",
        "    print(title)\n",
        "    print('#') \n",
        "    print('################################################################################')\n",
        "    print('') \n",
        "\n",
        "    eval(name_function)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}