{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_02.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K29I-OwCEYzW",
        "outputId": "db8b297c-a4b8-457a-b43f-7570135306c7"
      },
      "source": [
        "# Multi-class classification based on Softmax and Cross-Entropy using pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHCcwsI7XVCq"
      },
      "source": [
        "## import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYpVpQM7XVCr"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.transforms.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import os"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5jM5gzBXVCs"
      },
      "source": [
        "## load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqI7nNTSXVCt",
        "outputId": "8fdd4dfd-721f-46aa-a474-de89b1a28d85"
      },
      "source": [
        "directory_data  = './data/'\n",
        "filename_data   = 'assignment_06_data.npz'\n",
        "data            = np.load(os.path.join(directory_data, filename_data))\n",
        "\n",
        "x_train = data['x_train']\n",
        "y_train = data['y_train']\n",
        "\n",
        "x_test  = data['x_test']\n",
        "y_test  = data['y_test']\n",
        "\n",
        "num_data_train  = x_train.shape[0]\n",
        "num_data_test   = x_test.shape[0]\n",
        "\n",
        "print('*************************************************')\n",
        "print('size of x_train :', x_train.shape)\n",
        "print('size of y_train :', y_train.shape)\n",
        "print('*************************************************')\n",
        "print('size of x_test :', x_test.shape)\n",
        "print('size of y_test :', y_test.shape)\n",
        "print('*************************************************')\n",
        "print('number of training image :', x_train.shape[0])\n",
        "print('height of training image :', x_train.shape[1])\n",
        "print('width of training image :', x_train.shape[2])\n",
        "print('*************************************************')\n",
        "print('number of testing image :', x_test.shape[0])\n",
        "print('height of testing image :', x_test.shape[1])\n",
        "print('width of testing image :', x_test.shape[2])\n",
        "print('*************************************************')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "size of x_train : (20000, 32, 32)\n",
            "size of y_train : (20000,)\n",
            "*************************************************\n",
            "size of x_test : (8000, 32, 32)\n",
            "size of y_test : (8000,)\n",
            "*************************************************\n",
            "number of training image : 20000\n",
            "height of training image : 32\n",
            "width of training image : 32\n",
            "*************************************************\n",
            "number of testing image : 8000\n",
            "height of testing image : 32\n",
            "width of testing image : 32\n",
            "*************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyXqrWqJXVCv"
      },
      "source": [
        "## number of classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR750UBkXVCv",
        "outputId": "229ddb5d-08da-42e5-e55b-6bc37594fa11"
      },
      "source": [
        "print('*************************************************')\n",
        "print('number of classes :', len(set(y_train)))\n",
        "print('*************************************************')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "number of classes : 10\n",
            "*************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBiy6pHFXVCw"
      },
      "source": [
        "## hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDhTIXicXVCw"
      },
      "source": [
        "device          = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# number_epoch    = 10\n",
        "number_epoch    = 100\n",
        "size_minibatch  = 32\n",
        "learning_rate   = 0.001\n",
        "weight_decay    = 1e-2"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0i3pOVBXVCx"
      },
      "source": [
        "## custom data loader for the PyTorch framework"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oWaCdGdXVCx"
      },
      "source": [
        "class dataset(Dataset):\n",
        "    \n",
        "    def __init__(self, image, label):\n",
        "        \n",
        "        self.image  = image\n",
        "        self.label  = label.astype(np.long)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        image   = self.image[index, :, :]\n",
        "        label   = self.label[index, ]\n",
        "\n",
        "        image   = torch.FloatTensor(image).unsqueeze(dim=0)\n",
        "        label   = torch.LongTensor([label])\n",
        "\n",
        "        return image, label\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return self.image.shape[0]\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        images  = list()\n",
        "        labels  = list()\n",
        "\n",
        "        for b in batch:\n",
        "            images.append(b[0])\n",
        "            labels.append(b[1])\n",
        "\n",
        "        images  = torch.stack(images, dim=0)\n",
        "        labels  = torch.stack(labels, dim=0).squeeze()\n",
        "\n",
        "        return images, labels\n",
        "        "
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qijKTlLXVCz"
      },
      "source": [
        "## construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiUE52L1XVCz"
      },
      "source": [
        "dataset_train   = dataset(x_train, y_train)\n",
        "dataset_test    = dataset(x_test, y_test)\n",
        "\n",
        "dataloader_train    = torch.utils.data.DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, collate_fn=dataset_train.collate_fn)\n",
        "dataloader_test     = torch.utils.data.DataLoader(dataset_test, batch_size=size_minibatch, shuffle=True, drop_last=True, collate_fn=dataset_test.collate_fn)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EN9FrTBXVCz"
      },
      "source": [
        "## shape of the data when using the data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_bSNMNOXVC0",
        "outputId": "7c5a3ad5-76ce-449c-d1d2-12eb437feb13"
      },
      "source": [
        "image, label    = next(iter(dataloader_train))\n",
        "print('************************************************************')\n",
        "print('size of mini-batch of the image:', image.shape)\n",
        "print('************************************************************')\n",
        "print('size of mini-batch of the label:', label.shape)\n",
        "print('************************************************************')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************************************************************\n",
            "size of mini-batch of the image: torch.Size([32, 1, 32, 32])\n",
            "************************************************************\n",
            "size of mini-batch of the label: torch.Size([32])\n",
            "************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aU1KHtUjXVC0"
      },
      "source": [
        "## class for the neural network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDEIzw5uXVC1"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Classifier, self).__init__()\n",
        "    \n",
        "        self.layer1 = nn.Sequential( \n",
        "            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.Conv2d(in_channels=128, out_channels=4, kernel_size=1, padding=1, bias=True)\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential( \n",
        "            nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        self.layer3 = nn.Sequential( \n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "\n",
        "        self.layer4 = nn.Sequential( \n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=1, padding=1, bias=True)\n",
        "        )\n",
        "\n",
        "        self.layer5 = nn.Sequential( \n",
        "            nn.Conv2d(in_channels=16, out_channels=16,kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.Dropout2d(0.1)\n",
        "        )\n",
        "\n",
        "        self.layer6 = nn.Sequential( \n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=1, padding=1, bias=True),\n",
        "            nn.AvgPool2d(kernel_size=7),\n",
        "        )\n",
        "\n",
        "        self.feature    = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=128),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.Conv2d(in_channels=128, out_channels=4, kernel_size=1, padding=1, bias=True),\n",
        "\n",
        "            nn.Conv2d(in_channels=4, out_channels=16, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.Dropout2d(0.1),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(in_channels=32, out_channels=16, kernel_size=1, padding=1, bias=True),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=16,kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=16),\n",
        "            nn.Dropout2d(0.1),\n",
        "\n",
        "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1, bias=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.BatchNorm2d(num_features=32),\n",
        "            nn.Dropout2d(0.1),\n",
        "            nn.Conv2d(in_channels=32, out_channels=10, kernel_size=1, padding=1, bias=True),\n",
        "            nn.AvgPool2d(kernel_size=7),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "        )\n",
        "        self.network    = nn.Sequential(\n",
        "            self.feature,\n",
        "        )\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for m in self.network.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.constant_(m.weight, 0.01)\n",
        "                nn.init.constant_(m.bias, 1)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.constant_(m.weight, 0.01)\n",
        "                nn.init.constant_(m.bias, 1)\n",
        "\n",
        "    # def forward(self, x):\n",
        "    #     x = self.layer1(x)\n",
        "    #     x = self.layer2(x)\n",
        "    #     x = self.layer3(x)\n",
        "    #     x = self.layer4(x)\n",
        "    #     x = self.layer5(x)\n",
        "    #     x = self.layer6(x)\n",
        "    #     x = x.view(-1, 10)\n",
        "    #     return torch.nn.functional.log_softmax(x)\n",
        "\n",
        "    \n",
        "    def forward(self, input):\n",
        "        output = self.feature(input)\n",
        "        output = output.view(-1, 10)\n",
        "        return torch.nn.functional.log_softmax(output)\n",
        "\n",
        "  \n",
        "    # def __init__(self):\n",
        "    #     super(Classifier, self).__init__()\n",
        "\n",
        "    #     self.feature    = nn.Sequential(\n",
        "    #         nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "    #         nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    #         nn.ReLU(),\n",
        "\n",
        "    #         nn.Conv2d(in_channels=2, out_channels=4, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "    #         nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    #         nn.ReLU(),\n",
        "\n",
        "    #         nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True),\n",
        "    #         nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "    #         nn.ReLU(),\n",
        "    #     )\n",
        "\n",
        "    #     self.classifier = nn.Sequential(\n",
        "    #         nn.Linear(128, 64, bias=True),\n",
        "    #         nn.ReLU(),\n",
        "    #         nn.Linear(64, 10, bias=True),\n",
        "    #     )\n",
        "\n",
        "    #     self.network    = nn.Sequential(\n",
        "    #         self.feature,\n",
        "    #         nn.Flatten(),\n",
        "    #         self.classifier,\n",
        "    #     )\n",
        "\n",
        "    #     self.initialize()\n",
        "\n",
        "\n",
        "    # def initialize(self):\n",
        "\n",
        "    #     for m in self.network.modules():\n",
        "\n",
        "    #         if isinstance(m, nn.Conv2d):\n",
        "\n",
        "    #             nn.init.constant_(m.weight, 0.01)\n",
        "    #             nn.init.constant_(m.bias, 1)\n",
        "\n",
        "    #         elif isinstance(m, nn.Linear):\n",
        "\n",
        "    #             nn.init.constant_(m.weight, 0.01)\n",
        "    #             nn.init.constant_(m.bias, 1)\n",
        "\n",
        "\n",
        "    # def forward(self, input):\n",
        "\n",
        "    #     output = self.network(input)\n",
        "\n",
        "    #     return output"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxJxt4bnXVC2"
      },
      "source": [
        "## build network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Y_cnVyXVC2"
      },
      "source": [
        "classifier  = Classifier().to(device)\n",
        "optimizer   = torch.optim.SGD(classifier.parameters(), lr=learning_rate, weight_decay=weight_decay)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-kn0MoKXVC2"
      },
      "source": [
        "## print the defined neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNGdCEMVXVC2",
        "outputId": "bac6ab28-2dfc-4897-a88b-3e2f60f3ef74"
      },
      "source": [
        "print(classifier)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier(\n",
            "  (layer1): Sequential(\n",
            "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout2d(p=0.1, inplace=False)\n",
            "    (4): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout2d(p=0.1, inplace=False)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout2d(p=0.1, inplace=False)\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout2d(p=0.1, inplace=False)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (layer5): Sequential(\n",
            "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout2d(p=0.1, inplace=False)\n",
            "  )\n",
            "  (layer6): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout2d(p=0.1, inplace=False)\n",
            "    (4): Conv2d(32, 10, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
            "    (5): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
            "  )\n",
            "  (feature): Sequential(\n",
            "    (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (3): Dropout2d(p=0.1, inplace=False)\n",
            "    (4): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
            "    (5): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (6): ReLU(inplace=True)\n",
            "    (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): Dropout2d(p=0.1, inplace=False)\n",
            "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (13): Dropout2d(p=0.1, inplace=False)\n",
            "    (14): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): ReLU(inplace=True)\n",
            "    (16): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (17): Dropout2d(p=0.1, inplace=False)\n",
            "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
            "    (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): ReLU(inplace=True)\n",
            "    (22): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (23): Dropout2d(p=0.1, inplace=False)\n",
            "    (24): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (27): Dropout2d(p=0.1, inplace=False)\n",
            "    (28): Conv2d(32, 10, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
            "    (29): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
            "  )\n",
            "  (classifier): Sequential()\n",
            "  (network): Sequential(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): Dropout2d(p=0.1, inplace=False)\n",
            "      (4): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
            "      (5): Conv2d(4, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (8): Dropout2d(p=0.1, inplace=False)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (13): Dropout2d(p=0.1, inplace=False)\n",
            "      (14): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (15): ReLU(inplace=True)\n",
            "      (16): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (17): Dropout2d(p=0.1, inplace=False)\n",
            "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (19): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
            "      (20): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (21): ReLU(inplace=True)\n",
            "      (22): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (23): Dropout2d(p=0.1, inplace=False)\n",
            "      (24): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (25): ReLU(inplace=True)\n",
            "      (26): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (27): Dropout2d(p=0.1, inplace=False)\n",
            "      (28): Conv2d(32, 10, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1))\n",
            "      (29): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzwhG-3RXVC3"
      },
      "source": [
        "## compute the prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwKh3TVVXVC3"
      },
      "source": [
        "def compute_prediction(model, input):\n",
        "\n",
        "    prediction = model(input)\n",
        "\n",
        "    return prediction"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRLfZRGoXVC3"
      },
      "source": [
        "## compute the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-_1eYGYXVC3"
      },
      "source": [
        "def compute_loss(prediction, label):\n",
        "\n",
        "    criterion   = nn.CrossEntropyLoss()\n",
        "    loss        = criterion(prediction, label)\n",
        "    loss_value  = loss.item()\n",
        "\n",
        "    return loss, loss_value"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n941kU5TXVC4"
      },
      "source": [
        "## compute the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WljE_sWXVC4"
      },
      "source": [
        "def compute_accuracy(prediction, label):\n",
        "    # ================================================================================ \n",
        "    # complete the function body \n",
        "    \n",
        "    pred = torch.argmax(prediction, dim=1)\n",
        "    equal = torch.eq(pred, label)\n",
        "    accuracy    = (torch.sum(equal) / len(equal)).item()\n",
        "\n",
        "    # ================================================================================ \n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKVoEELrXVC4"
      },
      "source": [
        "## variables for the learning curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQvE1i9PXVC4"
      },
      "source": [
        "loss_mean_train     = np.zeros(number_epoch)\n",
        "loss_std_train      = np.zeros(number_epoch)\n",
        "accuracy_mean_train = np.zeros(number_epoch)\n",
        "accuracy_std_train  = np.zeros(number_epoch)\n",
        "\n",
        "loss_mean_test      = np.zeros(number_epoch)\n",
        "loss_std_test       = np.zeros(number_epoch)\n",
        "accuracy_mean_test  = np.zeros(number_epoch)\n",
        "accuracy_std_test   = np.zeros(number_epoch)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkGshUUcXVC4"
      },
      "source": [
        "## train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UblF32-oXVC4",
        "outputId": "68f44e15-37ec-40df-8882-5c5b34335c8d"
      },
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_train_epoch        = []\n",
        "    accuracy_train_epoch    = []\n",
        "\n",
        "    classifier.train()\n",
        "\n",
        "    for index_batch, (image_train, label_train) in enumerate(dataloader_train):\n",
        "\n",
        "        image_train = image_train.to(device)\n",
        "        label_train = label_train.to(device)\n",
        "        \n",
        "        prediction_train                = compute_prediction(classifier, image_train)\n",
        "        loss_train, loss_value_train    = compute_loss(prediction_train, label_train)\n",
        "        accuracy_train                  = compute_accuracy(prediction_train, label_train)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_train_epoch.append(loss_value_train)\n",
        "        accuracy_train_epoch.append(accuracy_train)\n",
        "\n",
        "    loss_mean_train[i]      = np.mean(loss_train_epoch)\n",
        "    loss_std_train[i]       = np.std(loss_train_epoch)\n",
        "\n",
        "    accuracy_mean_train[i]  = np.mean(accuracy_train_epoch)\n",
        "    accuracy_std_train[i]   = np.std(accuracy_train_epoch)\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_test_epoch        = []\n",
        "    accuracy_test_epoch    = []\n",
        "\n",
        "    classifier.eval()\n",
        "\n",
        "    for index_batch, (image_test, label_test) in enumerate(dataloader_test):\n",
        "\n",
        "        image_test = image_test.to(device)\n",
        "        label_test = label_test.to(device)\n",
        "        \n",
        "        prediction_test             = compute_prediction(classifier, image_test)\n",
        "        loss_test, loss_value_test  = compute_loss(prediction_test, label_test)\n",
        "        accuracy_test               = compute_accuracy(prediction_test, label_test)\n",
        "\n",
        "        loss_test_epoch.append(loss_value_test)\n",
        "        accuracy_test_epoch.append(accuracy_test)\n",
        "\n",
        "    loss_mean_test[i]      = np.mean(loss_test_epoch)\n",
        "    loss_std_test[i]       = np.std(loss_test_epoch)\n",
        "\n",
        "    accuracy_mean_test[i]  = np.mean(accuracy_test_epoch)\n",
        "    accuracy_std_test[i]   = np.std(accuracy_test_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
<<<<<<< HEAD
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:121: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            " 21%|██        | 21/100 [04:00<15:04, 11.45s/it]"
=======
            "  0%|          | 0/100 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  5%|▌         | 5/100 [00:58<18:25, 11.63s/it]"
>>>>>>> parent of a210aba (complete assignment06)
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdHM4HswXVC5"
      },
      "source": [
        "## plot curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMGLALONXVC6"
      },
      "source": [
        "def plot_curve_error(data_mean, data_std, x_label, y_label, title):\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    alpha = 0.3\n",
        "    \n",
        "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
        "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrVD1we5XVC6"
      },
      "source": [
        "def print_curve(data, index):\n",
        "    \n",
        "    for i in range(len(index)):\n",
        "\n",
        "        idx = index[i]\n",
        "        val = data[idx]\n",
        "\n",
        "        print('index = %2d, value = %12.10f' % (idx, val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo5VSG35XVC7"
      },
      "source": [
        "def get_data_last(data, index_start):\n",
        "\n",
        "    data_last = data[index_start:]\n",
        "\n",
        "    return data_last"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_ndei1FXVC7"
      },
      "source": [
        "def get_max_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.max()\n",
        "\n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKr-ANTwXVC8"
      },
      "source": [
        "def get_min_last_range(data, index_start):\n",
        "\n",
        "    data_range = get_data_last(data, index_start)\n",
        "    value = data_range.min()\n",
        "\n",
        "    return value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A02HIaybXVC8"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyMjXX8kXVC8"
      },
      "source": [
        "# functions for presenting the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmNt8FkCXVC9"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbOmjCXrXVC9"
      },
      "source": [
        "def function_result_01():\n",
        "\n",
        "    plot_curve_error(loss_mean_train, loss_std_train, 'epoch', 'loss', 'loss (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrOzEaw3XVC9"
      },
      "source": [
        "def function_result_02():\n",
        "\n",
        "    plot_curve_error(accuracy_mean_train, accuracy_std_train, 'epoch', 'accuracy', 'accuracy (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6_eEyFEXVC9"
      },
      "source": [
        "def function_result_03():\n",
        "    \n",
        "    plot_curve_error(loss_mean_test, loss_std_test, 'epoch', 'loss', 'loss (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV5dtWY9XVC-"
      },
      "source": [
        "def function_result_04():\n",
        "    \n",
        "    plot_curve_error(accuracy_mean_test, accuracy_std_test, 'epoch', 'accuracy', 'accuracy (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bzzq8OmsXVC-"
      },
      "source": [
        "def function_result_05():\n",
        "    \n",
        "    data_last = get_data_last(loss_mean_train, -10)\n",
        "    index = np.arange(0, 10) \n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBa33_N_XVC-"
      },
      "source": [
        "def function_result_06():\n",
        "    \n",
        "    data_last = get_data_last(accuracy_mean_train, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akejqxhSXVC_"
      },
      "source": [
        "def function_result_07():\n",
        "    \n",
        "    data_last = get_data_last(loss_mean_test, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgg3r2PPXVC_"
      },
      "source": [
        "def function_result_08():\n",
        "    \n",
        "    data_last = get_data_last(accuracy_mean_test, -10)\n",
        "    index = np.arange(0, 10)\n",
        "    print_curve(data_last, index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebLSvH0aXVC_"
      },
      "source": [
        "def function_result_09():\n",
        "    \n",
        "    value = get_max_last_range(accuracy_mean_train, -10)\n",
        "    print('best training accuracy = %12.10f' % (value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJe_T-CfXVC_"
      },
      "source": [
        "def function_result_10():\n",
        "    \n",
        "    value = get_max_last_range(accuracy_mean_test, -10)\n",
        "    print('best testing accuracy = %12.10f' % (value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB4S8CyKXVDA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dagKcdx3XVDA"
      },
      "source": [
        "# RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6mCxasWXVDA"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPl18L0QXVDA"
      },
      "source": [
        "## # 01. plot the training loss curve (mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY50cgnFXVDA"
      },
      "source": [
        "function_result_01()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFu2l24_XVDB"
      },
      "source": [
        "## # 02. plot the training accuracy curve (mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-3yNdyPXVDB"
      },
      "source": [
        "function_result_02()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FC8WYkvXVDB"
      },
      "source": [
        "## # 03. plot the testing loss curve (mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbPE1s1fXVDC"
      },
      "source": [
        "function_result_03()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz7kfTakXVDC"
      },
      "source": [
        "## # 04. plot the testing accuracy curve (mean, std)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lglNDGD8XVDC"
      },
      "source": [
        "function_result_04()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjirVVDVXVDD"
      },
      "source": [
        "## # 05. print the training (mean) loss over batches at last 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btmeVfOSXVDD"
      },
      "source": [
        "function_result_05()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XsRfVlSXVDE"
      },
      "source": [
        "## # 06. print the training (mean) accuracy over batches at last 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaiu5DQ5XVDE"
      },
      "source": [
        "function_result_06()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Nec_-ulXVDE"
      },
      "source": [
        "## # 07. print the testing (mean) loss over batches at last 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_bjiRuoXVDF"
      },
      "source": [
        "function_result_07()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJPy2AknXVDF"
      },
      "source": [
        "## # 08. print the testing (mean) accuracy over batches at last 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuT9Z22VXVDF"
      },
      "source": [
        "function_result_08()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "408lQPZjXVDF"
      },
      "source": [
        "## # 09. print the best training (mean) accuracy within the last 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_Gm9ex1XVDG"
      },
      "source": [
        "function_result_09()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjC78Q_VXVDG"
      },
      "source": [
        "## # 10. print the best testing (mean) accuracy within the last 10 epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_juJV3uXVDG"
      },
      "source": [
        "function_result_10()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}